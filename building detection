{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10088520,"sourceType":"datasetVersion","datasetId":6123952}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/skb197/building-edge-detection?scriptVersionId=211979970\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nfrom matplotlib import pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nroot_image_path = '/kaggle/input/map-red-images/map red roof (2).png'\n# https://www.google.com/maps/@20.854357,-156.3180319,187m/data=!3m1!1e3!5m1!1e2?authuser=0&entry=ttu&g_ep=EgoyMDI0MTEyNC4xIKXMDSoJLDEwMjExMjMzSAFQAw%3D%3D \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:51:54.048144Z","iopub.execute_input":"2024-12-09T03:51:54.048592Z","iopub.status.idle":"2024-12-09T03:51:55.546995Z","shell.execute_reply.started":"2024-12-09T03:51:54.048556Z","shell.execute_reply":"2024-12-09T03:51:55.545787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_images(image_path):\n    image = cv2.imread(image_path)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    return image_rgb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:51:55.549093Z","iopub.execute_input":"2024-12-09T03:51:55.549787Z","iopub.status.idle":"2024-12-09T03:51:55.555027Z","shell.execute_reply.started":"2024-12-09T03:51:55.549739Z","shell.execute_reply":"2024-12-09T03:51:55.55419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_image(image_name, title='images',cmap=None):\n    plt.figure(figsize=(30, 20))\n    plt.subplot(1, 3, 1)\n    plt.title(title)\n    if cmap==None:\n        plt.imshow(image_name)\n    else:\n        plt.imshow(image_name, cmap='gray')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:51:55.556042Z","iopub.execute_input":"2024-12-09T03:51:55.556434Z","iopub.status.idle":"2024-12-09T03:51:55.579733Z","shell.execute_reply.started":"2024-12-09T03:51:55.556375Z","shell.execute_reply":"2024-12-09T03:51:55.578602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#histogram\ndef show_histrogram(images):\n    hist = cv2.calcHist([images], [0], None, [256], [0, 256])\n    # Plot the histogram\n    plt.figure()\n    plt.title(\"Grayscale Image Histogram\")\n    plt.xlabel(\"Pixel Intensity\")\n    plt.ylabel(\"Frequency\")\n    plt.plot(hist, color=\"black\")\n    plt.xlim([0, 256])\n    plt.grid()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:51:55.582871Z","iopub.execute_input":"2024-12-09T03:51:55.583332Z","iopub.status.idle":"2024-12-09T03:51:55.603748Z","shell.execute_reply.started":"2024-12-09T03:51:55.583289Z","shell.execute_reply":"2024-12-09T03:51:55.602611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def replace_black(image, replacement_color=(255, 255, 255)):\n    # Define the range for black color\n    lower_black = np.array([0, 0, 0])\n    upper_black = np.array([50, 50, 50])\n\n    # Create a mask for black pixels\n    mask = cv2.inRange(image, lower_black, upper_black)\n    \n    # Replace black pixels with the replacement color\n    image[mask == 255] = replacement_color\n    return image\n\n# image = cv2.imread('/kaggle/input/map-red-images/map red roof (2).png')\n# replace_black(image)  # Replace black with white\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:51:55.605785Z","iopub.execute_input":"2024-12-09T03:51:55.60619Z","iopub.status.idle":"2024-12-09T03:51:55.630643Z","shell.execute_reply.started":"2024-12-09T03:51:55.606147Z","shell.execute_reply":"2024-12-09T03:51:55.629656Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\ndef detect_red_roofs_with_shadow_verification(image_path):\n    def read_images(image_path):\n        return cv2.imread(image_path)\n    \n    def display_image(image, title, cmap=None):\n        plt.figure(figsize=(8, 8))\n        plt.title(title)\n        if cmap:\n            plt.imshow(image, cmap=cmap)\n        else:\n            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n        plt.axis('off')\n        plt.show()\n\n    def replace_black(image_rgb):\n        # Replace pure black pixels with a small value\n        image_rgb[np.all(image_rgb == [0, 0, 0], axis=-1)] = [1, 1, 1]\n        return image_rgb\n\n    def show_histrogram(image):\n        plt.figure()\n        plt.hist(image.ravel(), bins=256, range=[0, 256])\n        plt.title(\"Histogram\")\n        plt.show()\n\n    def detect_shadows(image_rgb):\n        hsv = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2HSV)\n        lower_shadow = np.array([0, 0, 0])\n        upper_shadow = np.array([180, 255, 50])\n        shadow_mask = cv2.inRange(hsv, lower_shadow, upper_shadow)\n        return shadow_mask\n\n    image_rgb = read_images(image_path)\n    display_image(image_rgb, title=\"Original Image\")\n    original_rgb_image = image_rgb.copy()\n    image_rgb = replace_black(image_rgb)\n\n    R = image_rgb[:, :, 0].astype(np.float32)\n    G = image_rgb[:, :, 1].astype(np.float32)\n    color_invariant = (np.pi / 4) * np.arctan2(R - G, R + G)\n    normalized_invariant = cv2.normalize(color_invariant, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n    display_image(normalized_invariant, title=\"After Normalize Invariant\", cmap='gray')\n\n    show_histrogram(normalized_invariant)\n    _, binary_image = cv2.threshold(normalized_invariant, 156, 255, cv2.THRESH_BINARY)\n    display_image(binary_image, title=\"Thresholding at 156\", cmap='gray')\n\n    min_area = 300\n    max_area = 50000\n    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_image, connectivity=8)\n    filtered_image = np.zeros_like(binary_image)\n    \n    for i in range(1, num_labels):\n        area = stats[i, cv2.CC_STAT_AREA]\n        if min_area <= area <= max_area:\n            filtered_image[labels == i] = 255\n    display_image(filtered_image, title=\"After Area Verification\", cmap='gray')\n\n    # Shadow detection\n    shadow_mask = detect_shadows(image_rgb)\n    display_image(shadow_mask, title=\"Detected Shadows\", cmap='gray')\n\n    # Morphological operation: disc erosion\n    avg_area = np.mean([stats[i, cv2.CC_STAT_AREA] for i in range(1, num_labels)])\n    structuring_element_size = int(np.sqrt(avg_area / np.pi))\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (structuring_element_size, structuring_element_size))\n    eroded_shadow_mask = cv2.erode(shadow_mask, kernel, iterations=1)\n    display_image(eroded_shadow_mask, title=\"Eroded Shadow Mask\", cmap='gray')\n\n    # Shadow verification\n    verified_buildings = original_rgb_image.copy()\n    for i in range(1, num_labels):\n        area = stats[i, cv2.CC_STAT_AREA]\n        if min_area <= area <= max_area:\n            x, y = int(centroids[i][0]), int(centroids[i][1])\n            # Check if shadow centroid is close to building centroid\n            shadow_labels, _, shadow_stats, shadow_centroids = cv2.connectedComponentsWithStats(eroded_shadow_mask, connectivity=8)\n            for j in range(1, shadow_labels):\n                shadow_x, shadow_y = int(shadow_centroids[j][0]), int(shadow_centroids[j][1])\n                distance = np.sqrt((x - shadow_x)**2 + (y - shadow_y)**2)\n                if distance < structuring_element_size * 2:  # Threshold distance\n                    cv2.circle(verified_buildings, (x, y), structuring_element_size, (255, 0, 0), 2)  # Blue circle\n                    break\n            else:\n                cv2.rectangle(verified_buildings, (x - 10, y - 10), (x + 10, y + 10), (0, 0, 255), 2)  # Red rectangle\n    display_image(verified_buildings, title=\"Verified Buildings\")\n\n# Replace 'root_image_path' with the path to your image file\ndetect_red_roofs_with_shadow_verification('/kaggle/input/map-red-images/map red roof (2).png')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:57:44.070582Z","iopub.execute_input":"2024-12-09T03:57:44.070983Z","iopub.status.idle":"2024-12-09T03:57:47.190372Z","shell.execute_reply.started":"2024-12-09T03:57:44.070948Z","shell.execute_reply":"2024-12-09T03:57:47.189209Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def detect_red_roofs(image_path):\n    image_rgb = read_images(image_path)\n    display_image(image_rgb, title=\"Original Image\", cmap='gray')\n    original_rgb_image = image_rgb.copy()\n    image_rgb = replace_black(image_rgb)\n    R = image_rgb[:, :, 0].astype(np.float32)\n    G = image_rgb[:, :, 1].astype(np.float32)\n   \n    color_invariant = (np.pi / 4) * np.arctan2(R - G, R + G)\n    normalized_invariant = cv2.normalize(color_invariant, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n    display_image(normalized_invariant, title=\"After Normalize Invariant\", cmap='gray')\n\n    # Threshold to create a binary image\n    show_histrogram(normalized_invariant)\n    _, binary_image = cv2.threshold(normalized_invariant, 156, 255, cv2.THRESH_BINARY)\n    display_image(binary_image, title=\"Thresholding at 156\", cmap='gray')\n\n    min_area = 300\n    max_area = 50000\n    kernel_size = 3\n\n    # Find connected components\n    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_image, connectivity=8)\n    filtered_image = np.zeros_like(binary_image)\n    \n    for i in range(1, num_labels):\n        area = stats[i, cv2.CC_STAT_AREA]\n        if min_area <= area <= max_area:\n            filtered_image[labels == i] = 255\n    display_image(filtered_image, title=\"After Area Verification\", cmap='gray')\n   \n    \n    image_with_ticks = original_rgb_image.copy()\n    for i in range(1, num_labels):  \n        area = stats[i, cv2.CC_STAT_AREA]\n        if min_area <= area <= max_area: \n            x, y = int(centroids[i][0]), int(centroids[i][1])  \n            cv2.drawMarker(image_with_ticks, (x, y), color=(0, 0, 255), markerType=cv2.MARKER_CROSS, thickness=2)\n    display_image(image_with_ticks, title=\"Buildings Detected\", cmap=None)\n\n\n\ndetect_red_roofs(root_image_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T04:01:05.368183Z","iopub.execute_input":"2024-12-09T04:01:05.368586Z","iopub.status.idle":"2024-12-09T04:01:07.966965Z","shell.execute_reply.started":"2024-12-09T04:01:05.368553Z","shell.execute_reply":"2024-12-09T04:01:07.966008Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Flat Building Detection","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:51:59.072559Z","iopub.execute_input":"2024-12-09T03:51:59.072969Z","iopub.status.idle":"2024-12-09T03:51:59.985074Z","shell.execute_reply.started":"2024-12-09T03:51:59.072923Z","shell.execute_reply":"2024-12-09T03:51:59.983944Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def remove_vegetation_and_shadows(image):\n    \"\"\"\n    Convert vegetation (greenish areas) and shadows (dark areas) to white in the image.\n    \n    :param image: Original RGB image\n    :return: Image with vegetation and shadows converted to white\n    \"\"\"\n    # Convert the image to HSV color space\n    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n    \n    # Remove vegetation (greenish areas)\n    lower_green = np.array([35, 40, 40])  # Lower bound for green\n    upper_green = np.array([85, 255, 255])  # Upper bound for green\n    green_mask = cv2.inRange(hsv_image, lower_green, upper_green)\n    \n    # Convert green areas to white\n    image_with_white_vegetation = image.copy()\n    image_with_white_vegetation[green_mask > 0] = [255, 255, 255]  # Set green areas to white\n    \n    # Remove shadows (dark areas)\n    lower_shadow = np.array([0, 0, 0])  # Shadows typically have low brightness\n    upper_shadow = np.array([255, 255, 100])  # Keeping mid-high brightness areas\n    shadow_mask = cv2.inRange(hsv_image, lower_shadow, upper_shadow)\n    \n    # Convert shadow areas to white\n    image_with_white_vegetation_shadows = image_with_white_vegetation.copy()\n    image_with_white_vegetation_shadows[shadow_mask > 0] = [255, 255, 255]  # Set shadow areas to white\n    \n    return image_with_white_vegetation_shadows","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:51:59.986325Z","iopub.execute_input":"2024-12-09T03:51:59.986763Z","iopub.status.idle":"2024-12-09T03:51:59.994433Z","shell.execute_reply.started":"2024-12-09T03:51:59.986731Z","shell.execute_reply":"2024-12-09T03:51:59.993088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def detect_building_edges(image):\n    \"\"\"\n    Detect building edges using a segmentation-based approach.\n    \n    :param image: Processed image with vegetation and shadows removed\n    :return: Image with detected building edges\n    \"\"\"\n    # Convert to grayscale\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    \n    # Apply Gaussian blur to reduce noise\n    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n    blurred = cv2.GaussianBlur(blurred, (5, 5), 0)\n    \n    # Perform Canny edge detection\n    edges = cv2.Canny(blurred, 50, 200) \n    \n    # Perform K-Means clustering to segment the image\n    X = edges.reshape(-1, 1)\n    kmeans = KMeans(n_clusters=3, random_state=42).fit(X)\n    segmented = kmeans.labels_.reshape(edges.shape)\n    \n    # Find contours in the segmented image\n    contours, _ = cv2.findContours(\n        (segmented == 1).astype(np.uint8) * 255, \n        cv2.RETR_TREE, \n        cv2.CHAIN_APPROX_SIMPLE\n    )\n    \n    # Create a copy of the original image to draw the edges\n    edge_image = image.copy()\n    \n    # Draw the detected building edges\n    cv2.drawContours(edge_image, contours, -1, (0, 255, 0), 2)\n    \n    return edge_image, contours","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:51:59.995835Z","iopub.execute_input":"2024-12-09T03:51:59.996189Z","iopub.status.idle":"2024-12-09T03:52:00.011503Z","shell.execute_reply.started":"2024-12-09T03:51:59.996152Z","shell.execute_reply":"2024-12-09T03:52:00.010439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_angle(line1, line2):\n    \"\"\"\n    Calculate the angle between two lines represented as vectors.\n    \n    :param line1: First line represented as (x1, y1) and (x2, y2)\n    :param line2: Second line represented as (x1, y1) and (x2, y2)\n    :return: Angle in degrees between the two lines\n    \"\"\"\n    # Line vectors\n    vector1 = np.array([line1[2] - line1[0], line1[3] - line1[1]])\n    vector2 = np.array([line2[2] - line2[0], line2[3] - line2[1]])\n\n    # Dot product and magnitude of vectors\n    dot_product = np.dot(vector1, vector2)\n    norm1 = np.linalg.norm(vector1)\n    norm2 = np.linalg.norm(vector2)\n\n    # Calculate the cosine of the angle\n    cos_angle = dot_product / (norm1 * norm2)\n\n    # Calculate the angle in radians and convert to degrees\n    angle = np.arccos(np.clip(cos_angle, -1.0, 1.0)) * (180.0 / np.pi)\n    return angle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:52:00.014271Z","iopub.execute_input":"2024-12-09T03:52:00.014621Z","iopub.status.idle":"2024-12-09T03:52:00.028402Z","shell.execute_reply.started":"2024-12-09T03:52:00.014589Z","shell.execute_reply":"2024-12-09T03:52:00.027202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def detect_perpendicular_lines(lines, angle_threshold=10):\n    \"\"\"\n    Detect pairs of perpendicular lines from the list of lines based on angle.\n    \n    :param lines: List of lines in the form [(x1, y1, x2, y2)]\n    :param angle_threshold: Angle threshold for perpendicularity detection\n    :return: List of perpendicular line pairs\n    \"\"\"\n    perpendicular_pairs = []\n    \n    for i, line1 in enumerate(lines):\n        for j, line2 in enumerate(lines):\n            if i >= j:\n                continue\n            \n            angle = calculate_angle(line1, line2)\n            if 80 <= angle <= 100:  # Angle between 80 and 100 degrees is perpendicular\n                perpendicular_pairs.append((line1, line2))\n                \n    return perpendicular_pairs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:52:00.029839Z","iopub.execute_input":"2024-12-09T03:52:00.030209Z","iopub.status.idle":"2024-12-09T03:52:00.042001Z","shell.execute_reply.started":"2024-12-09T03:52:00.030174Z","shell.execute_reply":"2024-12-09T03:52:00.040846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def detect_parallel_lines(lines, angle_threshold=10, distance_threshold=20):\n    \"\"\"\n    Detect pairs of parallel lines based on angle and distance.\n    \n    :param lines: List of lines in the form [(x1, y1, x2, y2)]\n    :param angle_threshold: Angle threshold for parallelity detection\n    :param distance_threshold: Distance threshold for parallel line distance\n    :return: List of parallel line pairs\n    \"\"\"\n    parallel_pairs = []\n    \n    for i, line1 in enumerate(lines):\n        for j, line2 in enumerate(lines):\n            if i >= j:\n                continue\n            \n            angle = calculate_angle(line1, line2)\n            if angle < angle_threshold:\n                # Calculate the distance between the two parallel lines\n                distance = np.abs((line2[2] - line2[0]) * (line1[1] - line2[1]) - (line2[3] - line2[1]) * (line1[0] - line2[0])) / np.linalg.norm([line2[2] - line2[0], line2[3] - line2[1]])\n                \n                if distance < distance_threshold:\n                    parallel_pairs.append((line1, line2))\n    \n    return parallel_pairs\n\n# Read the image\nimage = cv2.imread('/kaggle/input/map-red-images/map red roof (2).png')\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Remove vegetation and shadows from the image\nimage_no_vegetation_shadows = remove_vegetation_and_shadows(image_rgb)\n\n# Sharpen the image\nsharpening_kernel = np.array([[0, -1, 0],\n                               [-1, 5,-1],\n                               [0, -1, 0]])\nsharpened_image = cv2.filter2D(image_rgb, -1, sharpening_kernel)\n\n# Detect building edges\nedge_image, contours = detect_building_edges(sharpened_image)\n\n# Create a list of detected lines (assuming edges represent lines)\nlines = [(contour[0][0][0], contour[0][0][1], contour[-1][0][0], contour[-1][0][1]) for contour in contours]\n\n# Detect perpendicular lines\nperpendicular_pairs = detect_perpendicular_lines(lines)\n\n# Detect parallel lines\nparallel_pairs = detect_parallel_lines(lines)\n\n# Visualization\nplt.figure(figsize=(100, 75))\n\n# Display the original, processed, and detected edges\nplt.subplot(2, 3, 1)\nplt.imshow(image_rgb)\nplt.title('Original Image')\nplt.axis('off')\n\nplt.subplot(2, 3, 2)\nplt.imshow(image_no_vegetation_shadows)\nplt.title('No Vegetation & Shadows')\nplt.axis('off')\n\nplt.subplot(2, 3, 3)\nplt.imshow(sharpened_image)\nplt.title('Sharpened Image')\nplt.axis('off')\n\nplt.subplot(2, 3, 4)\nplt.imshow(edge_image)\nplt.title('Detected Building Edges')\nplt.axis('off')\n\n# Highlight perpendicular and parallel lines\nhighlighted_image = edge_image.copy()\nfor line1, line2 in perpendicular_pairs:\n    cv2.line(highlighted_image, (line1[0], line1[1]), (line1[2], line1[3]), (255, 0, 0), 2)\n    cv2.line(highlighted_image, (line2[0], line2[1]), (line2[2], line2[3]), (255, 0, 0), 2)\n\nfor line1, line2 in parallel_pairs:\n    cv2.line(highlighted_image, (line1[0], line1[1]), (line1[2], line1[3]), (0, 0, 255), 2)\n    cv2.line(highlighted_image, (line2[0], line2[1]), (line2[2], line2[3]), (0, 0, 255), 2)\n\nplt.subplot(2, 3, 5)\nplt.imshow(highlighted_image)\nplt.title('Highlighted Perpendicular & Parallel Lines')\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:52:00.043352Z","iopub.execute_input":"2024-12-09T03:52:00.043685Z","iopub.status.idle":"2024-12-09T03:53:05.02093Z","shell.execute_reply.started":"2024-12-09T03:52:00.043655Z","shell.execute_reply":"2024-12-09T03:53:05.019577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef display_images(images, titles):\n    plt.figure(figsize=(15, 10))\n    for i, (img, title) in enumerate(zip(images, titles)):\n        plt.subplot(2, len(images)//2 + 1, i + 1)\n        if len(img.shape) == 2:\n            plt.imshow(img, cmap='gray')\n        else:\n            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n        plt.title(title)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# Step 1: Input RGB Image\ninput_image = cv2.imread('/kaggle/input/map-red-images/Screenshot 2024-12-03 190357.png') # Replace with your image path\ninput_image_rgb = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n\n# Step 2: Image Sharpening\nkernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]) # Sharpening kernel\nsharpened_image = cv2.filter2D(input_image, -1, kernel)\n\n# Step 3: Edge Detection\ngray_image = cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2GRAY)\nedges = cv2.Canny(gray_image, 100, 200)\n\n# Step 4: Line Generation and Merging\nlines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=30, maxLineGap=5)\nline_image = np.zeros_like(input_image)\nif lines is not None:\n    for line in lines:\n        x1, y1, x2, y2 = line[0]\n        cv2.line(line_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n\nmerged_lines_image = cv2.addWeighted(input_image, 0.8, line_image, 1, 0)\n\n# Steps 5-6: Perpendicular/Parallel Detection and Shadow Verification (Placeholder)\n# More advanced geometric logic is required here. We'll outline areas as detected rectangles for simplicity.\ncontours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\nshadow_verified_image = input_image.copy()\nfor contour in contours:\n    approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)\n    if len(approx) == 4: # Approximate rectangles\n        cv2.drawContours(shadow_verified_image, [approx], 0, (0, 0, 255), 2)\n\n# Display results at each step\nsteps = [input_image_rgb, sharpened_image, edges, merged_lines_image, shadow_verified_image]\ntitles = ['Input RGB Image', 'Image Sharpening', 'Edge Detection', 'Line Merging', 'Shadow Verification']\ndisplay_images(steps, titles)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:53:05.022655Z","iopub.execute_input":"2024-12-09T03:53:05.023004Z","iopub.status.idle":"2024-12-09T03:53:06.841742Z","shell.execute_reply.started":"2024-12-09T03:53:05.022971Z","shell.execute_reply":"2024-12-09T03:53:06.840373Z"}},"outputs":[],"execution_count":null}]}